{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Machine Translation for Cantonese-English Language Pair\n",
        "Florence Yuen\n",
        "- Uses datasets from Tatoeba and OpenSubtitles to load Cantonese-English language pair data\n",
        "- Preprocess character-based and Jyutping romanized Cantonese data by tokenizing and doing data cleansing\n",
        "- Apply mBART-50 pre-trained multilingual NMT model\n",
        "- Compare and evaluate greedy and beam search decoding strategies\n",
        "- Save translation outputs to csv file\n",
        "- Generates BLEU scores to evaluate and compare the two decoding strategies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a278ff15",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (4.54.1)\n",
            "Requirement already satisfied: sentencepiece in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: torch in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.7.1)\n",
            "Requirement already satisfied: pandas in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (2.3.1)\n",
            "Requirement already satisfied: sacrebleu in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (2.5.1)\n",
            "Requirement already satisfied: datasets in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (4.0.0)\n",
            "Requirement already satisfied: pypinyin in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (0.55.0)\n",
            "Requirement already satisfied: epitran in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from -r requirements.txt (line 8)) (1.26.0)\n",
            "Requirement already satisfied: hf_xet in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from -r requirements.txt (line 9)) (1.1.5)\n",
            "Requirement already satisfied: protobuf in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from -r requirements.txt (line 10)) (6.31.1)\n",
            "Requirement already satisfied: ipywidgets in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from -r requirements.txt (line 11)) (8.1.7)\n",
            "Collecting matplotlib (from -r requirements.txt (line 12))\n",
            "  Downloading matplotlib-3.10.5-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (2.3.2)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (2025.7.34)\n",
            "Requirement already satisfied: requests in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (1.14.0)\n",
            "Requirement already satisfied: networkx in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (3.5)\n",
            "Requirement already satisfied: jinja2 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (3.1.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: portalocker in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from sacrebleu->-r requirements.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from sacrebleu->-r requirements.txt (line 5)) (0.9.0)\n",
            "Requirement already satisfied: colorama in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from sacrebleu->-r requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: lxml in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from sacrebleu->-r requirements.txt (line 5)) (6.0.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from datasets->-r requirements.txt (line 6)) (21.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from datasets->-r requirements.txt (line 6)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from datasets->-r requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from datasets->-r requirements.txt (line 6)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (3.12.15)\n",
            "Requirement already satisfied: setuptools in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from epitran->-r requirements.txt (line 8)) (65.5.0)\n",
            "Requirement already satisfied: panphon>=0.20 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from epitran->-r requirements.txt (line 8)) (0.22.2)\n",
            "Requirement already satisfied: marisa-trie in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from epitran->-r requirements.txt (line 8)) (1.2.1)\n",
            "Requirement already satisfied: jamo in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from epitran->-r requirements.txt (line 8)) (0.4.1)\n",
            "Requirement already satisfied: comm>=0.1.3 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 11)) (0.2.3)\n",
            "Requirement already satisfied: ipython>=6.1.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 11)) (9.4.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 11)) (5.14.3)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 11)) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 11)) (3.0.15)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->-r requirements.txt (line 12))\n",
            "  Downloading contourpy-1.3.3-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 12))\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->-r requirements.txt (line 12))\n",
            "  Downloading fonttools-4.59.0-cp311-cp311-win_amd64.whl.metadata (110 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->-r requirements.txt (line 12))\n",
            "  Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
            "Collecting pillow>=8 (from matplotlib->-r requirements.txt (line 12))\n",
            "  Downloading pillow-11.3.0-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib->-r requirements.txt (line 12))\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: decorator in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (0.1.7)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (2.19.2)\n",
            "Requirement already satisfied: stack_data in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (0.6.3)\n",
            "Requirement already satisfied: wcwidth in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (0.8.4)\n",
            "Requirement already satisfied: unicodecsv in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from panphon>=0.20->epitran->-r requirements.txt (line 8)) (0.14.1)\n",
            "Requirement already satisfied: editdistance in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from panphon>=0.20->epitran->-r requirements.txt (line 8)) (0.8.1)\n",
            "Requirement already satisfied: munkres in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from panphon>=0.20->epitran->-r requirements.txt (line 8)) (1.1.4)\n",
            "Requirement already satisfied: six>=1.5 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 1)) (2025.7.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: pywin32>=226 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from portalocker->sacrebleu->-r requirements.txt (line 5)) (311)\n",
            "Requirement already satisfied: executing>=1.2.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in d:\\florence\\homework\\universityofwaterloo\\fourthyear\\cs486\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 11)) (0.2.3)\n",
            "Downloading matplotlib-3.10.5-cp311-cp311-win_amd64.whl (8.1 MB)\n",
            "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 8.1/8.1 MB 38.6 MB/s  0:00:00\n",
            "Downloading contourpy-1.3.3-cp311-cp311-win_amd64.whl (225 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.59.0-cp311-cp311-win_amd64.whl (2.3 MB)\n",
            "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.3/2.3 MB 31.7 MB/s  0:00:00\n",
            "Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
            "Downloading pillow-11.3.0-cp311-cp311-win_amd64.whl (7.0 MB)\n",
            "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 7.0/7.0 MB 48.0 MB/s  0:00:00\n",
            "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "\n",
            "   ----- ---------------------------------- 1/7 [pillow]\n",
            "   ----- ---------------------------------- 1/7 [pillow]\n",
            "   ----- ---------------------------------- 1/7 [pillow]\n",
            "   ----- ---------------------------------- 1/7 [pillow]\n",
            "   ----------- ---------------------------- 2/7 [kiwisolver]\n",
            "   ----------------- ---------------------- 3/7 [fonttools]\n",
            "   ----------------- ---------------------- 3/7 [fonttools]\n",
            "   ----------------- ---------------------- 3/7 [fonttools]\n",
            "   ----------------- ---------------------- 3/7 [fonttools]\n",
            "   ----------------- ---------------------- 3/7 [fonttools]\n",
            "   ----------------- ---------------------- 3/7 [fonttools]\n",
            "   ----------------- ---------------------- 3/7 [fonttools]\n",
            "   ----------------- ---------------------- 3/7 [fonttools]\n",
            "   ----------------- ---------------------- 3/7 [fonttools]\n",
            "   ----------------- ---------------------- 3/7 [fonttools]\n",
            "   ----------------- ---------------------- 3/7 [fonttools]\n",
            "   ----------------- ---------------------- 3/7 [fonttools]\n",
            "   ----------------- ---------------------- 3/7 [fonttools]\n",
            "   ---------------------------- ----------- 5/7 [contourpy]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------- ----- 6/7 [matplotlib]\n",
            "   ---------------------------------------- 7/7 [matplotlib]\n",
            "\n",
            "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.0 kiwisolver-1.4.8 matplotlib-3.10.5 pillow-11.3.0 pyparsing-3.2.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93363c64",
      "metadata": {},
      "source": [
        "## Load Pretrained mBART-50 NMT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1df670ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # for progress bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cd541246",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer_nllb = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
        "model_nllb = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79483bff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Models below no longer used due to ineffectivenss of model for Cantonese\n",
        "# from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "\n",
        "# # Import the tokenizer\n",
        "# model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "# tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
        "# model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
        "# tokenizer.src_lang = \"yue_Hant\"\n",
        "# tokenizer.tgt_lang = \"en_XX\"\n",
        "\n",
        "# from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
        "\n",
        "# model_name_m2m = \"facebook/m2m100_418M\"\n",
        "# tokenizer_m2m = M2M100Tokenizer.from_pretrained(model_name_m2m)\n",
        "# model_m2m = M2M100ForConditionalGeneration.from_pretrained(model_name_m2m).to(device)\n",
        "\n",
        "# Load MarianMT Model\n",
        "# from transformers import MarianTokenizer, MarianMTModel\n",
        "\n",
        "# model_name_mar = \"Helsinki-NLP/opus-mt-yue-en\"\n",
        "# tokenizer_mar = MarianTokenizer.from_pretrained(model_name_mar)\n",
        "# model_mar = MarianMTModel.from_pretrained(model_name_mar).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6913af26",
      "metadata": {},
      "source": [
        "## Load Dataset from Tatoeba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "abf5d9b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "408b9b7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Manually load downloaded .en and .yue files, apply pre-processing to clean the text\n",
        "def load_parallel_corpus(cantonese_file, english_file, max_lines=None):\n",
        "    # Open the cantonese and english files\n",
        "    with open(cantonese_file, encoding='utf-8') as f_yue, open(english_file, encoding='utf-8') as f_en:\n",
        "        yue_lines = f_yue.readlines()\n",
        "        en_lines = f_en.readlines()\n",
        "\n",
        "    # Ensure that there is the same line count\n",
        "    if max_lines:\n",
        "        yue_lines = yue_lines[:max_lines]\n",
        "        en_lines = en_lines[:max_lines]\n",
        "\n",
        "    assert len(yue_lines) == len(en_lines), \"Line count mismatch!\"\n",
        "\n",
        "    #Apply preprocessing to clean the text \n",
        "    def clean_text(text):\n",
        "        # Remove brackets\n",
        "        text = re.sub(r'\\[[^\\]]*\\]', '', text)\n",
        "        text = re.sub(r'\\([^\\)]*\\)', '', text)\n",
        "        \n",
        "        # Normalize whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text.strip()\n",
        "\n",
        "    # Clean each line of text for both cantonese and english files\n",
        "    yue_lines = [clean_text(line) for line in yue_lines]\n",
        "    en_lines = [clean_text(line) for line in en_lines]\n",
        "\n",
        "    # Build the DataFrame and drop empty lines\n",
        "    df = pd.DataFrame({'cantonese': yue_lines, 'english': en_lines})\n",
        "    df = df[(df['cantonese'] != '') & (df['english'] != '')].reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "def load_all_datasets(model_name):\n",
        "    dataframes={}\n",
        "    files = [\n",
        "        {\n",
        "            \"dataset_name\": \"Tatoeba\",\n",
        "            \"cantonese_file\": 'en-yue.txt/Tatoeba.en-yue.yue',\n",
        "            \"english_file\": 'en-yue.txt/Tatoeba.en-yue.en'\n",
        "        },\n",
        "        {\n",
        "            \"dataset_name\": \"Open_Subtitles\",\n",
        "            \"cantonese_file\": 'open-subtitles_en-yue.txt/OpenSubtitles.en-yue.yue',\n",
        "            \"english_file\": 'open-subtitles_en-yue.txt/OpenSubtitles.en-yue.en'\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    max_lines=1000\n",
        "    for dataset in files:\n",
        "        df = load_parallel_corpus(cantonese_file=dataset[\"cantonese_file\"], english_file=dataset[\"english_file\"], max_lines=max_lines)\n",
        "        df_name = f\"{model_name}_{dataset['dataset_name']}\"\n",
        "        dataframes[df_name] = df\n",
        "    return dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "06324449",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             cantonese                                        english\n",
            "0              我要去瞓覺喇。                         I have to go to sleep.\n",
            "1  我話唔定做一陣就會放棄，走去瞓晏覺算。       I may give up soon and just nap instead.\n",
            "2       我不嬲都鍾意啲神秘啲嘅人物。     I always liked mysterious characters more.\n",
            "3   雖然佢講咗對唔住，但係我都仲係好嬲。  Even though he apologized, I'm still furious.\n",
            "4               我唯有係等。                               I can only wait.\n"
          ]
        }
      ],
      "source": [
        "# # Load Tatoeba dataset\n",
        "df = load_parallel_corpus('en-yue.txt/Tatoeba.en-yue.yue', 'en-yue.txt/Tatoeba.en-yue.en', max_lines=1000)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5185f99b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        cantonese                                            english\n",
            "0              你看                                              Look.\n",
            "1            笑死我了                                 - That kills me. -\n",
            "2  來整蠱他吧,讓他見識最佳拍檔  Come on, we'll fix him. Let's give him the old...\n",
            "3        你還不會用腦嗎?                            Won't you ever grow up?\n",
            "4              喂喂                                 - What? - Yoo-hoo!\n"
          ]
        }
      ],
      "source": [
        "# Load 1000 lines from OpenSubtitles dataset (downloaded from Opus)\n",
        "df_Open_Subtitles = load_parallel_corpus('open-subtitles_en-yue.txt/OpenSubtitles.en-yue.yue', 'open-subtitles_en-yue.txt/OpenSubtitles.en-yue.en', max_lines=1000)\n",
        "print(df_Open_Subtitles.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dbd172e",
      "metadata": {},
      "source": [
        "## Define Translation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "51e51a9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Translation function with tydm to add a loading progress bar for insights using mBART50 model\n",
        "def translate(texts, beam=1, batch_size=16):\n",
        "    translations = []\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    \n",
        "    # Devide into batches so that the progress/ percentage is shown too\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Translating\"):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        inputs = tokenizer(batch, padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = model.generate(\n",
        "                **inputs,\n",
        "                max_length=128,\n",
        "                num_beams=beam,\n",
        "                no_repeat_ngram_size=2\n",
        "            )\n",
        "        batch_translations = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "        translations.extend(batch_translations)\n",
        "    return translations\n",
        "\n",
        "# Translation function with model and tokenizer being passed in\n",
        "def translate_select_model(texts, tokenizer, model, beam=1, batch_size=16, device=\"cpu\", src_lang=None, tgt_lang=None):\n",
        "    translations = []\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    if src_lang:\n",
        "        tokenizer.src_lang = src_lang # set source language to cantonese\n",
        "    \n",
        "    forced_bos_token_id = None\n",
        "    if tgt_lang:\n",
        "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
        "\n",
        "    \n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Translating\"):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        inputs = tokenizer(batch, padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = model.generate(\n",
        "                **inputs,\n",
        "                forced_bos_token_id = forced_bos_token_id,\n",
        "                # forced_bos_token_id=tokenizer.get_lang_id(\"en\"),  # Force target language to English\n",
        "                max_length=128,\n",
        "                num_beams=beam,\n",
        "                no_repeat_ngram_size=2\n",
        "            )\n",
        "        batch_translations = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "        translations.extend(batch_translations)\n",
        "        if i==0:\n",
        "            print(f\"Initial translations: {batch_translations}\")\n",
        "    return translations\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4263c0e",
      "metadata": {},
      "source": [
        "## Translate & Compare Decoding Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcba1fc8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'NLLB_7_Tatoeba':                cantonese                                            english\n",
            "0                我要去瞓覺喇。                             I have to go to sleep.\n",
            "1    我話唔定做一陣就會放棄，走去瞓晏覺算。           I may give up soon and just nap instead.\n",
            "2         我不嬲都鍾意啲神秘啲嘅人物。         I always liked mysterious characters more.\n",
            "3     雖然佢講咗對唔住，但係我都仲係好嬲。      Even though he apologized, I'm still furious.\n",
            "4                 我唯有係等。                                   I can only wait.\n",
            "..                   ...                                                ...\n",
            "995            呢件外套無衫袋㗎。                          This coat hasn't pockets.\n",
            "996     呢隻蛋糕真係冇啲人講到咁好食囉。  This cake doesn't really live up to its reputa...\n",
            "997        呢條規則唔係幾時都啱用㗎。             This rule doesn't apply to every case.\n",
            "998           呢部相機冇嗰部咁貴。       This camera is less expensive than that one.\n",
            "999   你可唔可以用呢部相機幫我哋影幅相呀？   Would you take a picture of us with this camera?\n",
            "\n",
            "[1000 rows x 2 columns], 'NLLB_7_Open_Subtitles':           cantonese                                            english\n",
            "0                你看                                              Look.\n",
            "1              笑死我了                                 - That kills me. -\n",
            "2    來整蠱他吧,讓他見識最佳拍檔  Come on, we'll fix him. Let's give him the old...\n",
            "3          你還不會用腦嗎?                            Won't you ever grow up?\n",
            "4                喂喂                                 - What? - Yoo-hoo!\n",
            "..              ...                                                ...\n",
            "977    你的共鸣有点单方面 滚开              - Your empathy is a little one-sided.\n",
            "978              好了                                           Alright!\n",
            "979        我假设你是指我吧                         I assume you mean me, too?\n",
            "980        甜心，这个很可爱                       On you it looks cute, sugar.\n",
            "981          你会办妥一切              Well, you certainly fixed everything!\n",
            "\n",
            "[982 rows x 2 columns]}\n"
          ]
        }
      ],
      "source": [
        "# Setup NLLB translation\n",
        "def translate_nllb(beam=1):\n",
        "    translate_select_model(\n",
        "        df_nllb_7['NLLB_7_Open_Subtitles']['cantonese'].tolist(), \n",
        "        tokenizer_nllb, model_nllb, \n",
        "        beam=beam, batch_size=16, \n",
        "        device=device, \n",
        "        src_lang=\"yue_Hant\", \n",
        "        tgt_lang= \"eng_Latn\"\n",
        "    )\n",
        "    \n",
        "# Run translations for greedy and beam search algorithm using Tatoeba dataset\n",
        "df_nllb_7 = load_all_datasets(\"NLLB_7\")\n",
        "\n",
        "# beam size of 7\n",
        "print(df_nllb_7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "7e354080",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating:   2%|▏         | 1/62 [00:11<11:55, 11.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial translations: ['You see.', 'It made me laugh.', \"Let's fix him up and show him the best shot.\", \"You're not going to use your brain?\", 'Oh, my God.', 'Give it to me.', 'Get out of the way.', 'A self-righteous asshole.', \"That's good.\", 'See you again.', 'I got you, you little bastards, get out of here.', \"Don't ever come back.\", \"Hey, what's going on?\", 'Okay, hold your hands, you... shoot him, and continue the war plan.', 'Come on now.', 'Let me wait for you...']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating: 100%|██████████| 62/62 [14:41<00:00, 14.22s/it]\n",
            "Translating:   2%|▏         | 1/62 [00:13<13:15, 13.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial translations: ['You see.', 'It made me laugh.', \"Let's fix him up and show him the best shot.\", \"You're not going to use your brain?\", 'Oh, my God.', 'Give it to me.', 'Get out of the way.', 'A self-righteous asshole.', \"That's good.\", 'See you again.', 'I got you, you little bastards, get out of here.', \"Don't ever come back.\", \"Hey, what's going on?\", 'Okay, hold your hands, you... shoot him, and continue the war plan.', 'Come on now.', 'Let me wait for you...']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating: 100%|██████████| 62/62 [13:48<00:00, 13.37s/it]\n"
          ]
        }
      ],
      "source": [
        "df_nllb_3 = load_all_datasets(\"NLLB_3\")\n",
        "df_nllb_3['NLLB_3_Open_Subtitles']['beam'] = translate_nllb(beam=3)\n",
        "df_nllb_3['NLLB_3_Tatoeba']['beam'] = translate_nllb(beam=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "c56b304a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating:   0%|          | 0/62 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating:   2%|▏         | 1/62 [00:27<28:19, 27.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial translations: ['You see.', 'It made me laugh.', \"Let's fix him up and show him the best shot.\", \"Aren't you going to use your brain?\", 'Oh, my God.', 'Give it to me.', 'Get out of the way.', 'A self-righteous asshole.', \"That's good.\", 'See you again.', 'Get it, you little bastards, get out of here.', \"Don't ever come back.\", \"Hey, what's going on?\", 'Hey, hold your hands, you... shoot him and keep planning the war.', 'Come on now.', 'Let me wait for you...']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating: 100%|██████████| 62/62 [32:15<00:00, 31.22s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cantonese</th>\n",
              "      <th>english</th>\n",
              "      <th>beam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>你看</td>\n",
              "      <td>Look.</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>笑死我了</td>\n",
              "      <td>- That kills me. -</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>來整蠱他吧,讓他見識最佳拍檔</td>\n",
              "      <td>Come on, we'll fix him. Let's give him the old...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>你還不會用腦嗎?</td>\n",
              "      <td>Won't you ever grow up?</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>喂喂</td>\n",
              "      <td>- What? - Yoo-hoo!</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        cantonese                                            english  beam\n",
              "0              你看                                              Look.  None\n",
              "1            笑死我了                                 - That kills me. -  None\n",
              "2  來整蠱他吧,讓他見識最佳拍檔  Come on, we'll fix him. Let's give him the old...  None\n",
              "3        你還不會用腦嗎?                            Won't you ever grow up?  None\n",
              "4              喂喂                                 - What? - Yoo-hoo!  None"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_nllb_7['NLLB_7_Open_Subtitles']['beam'] = translate_nllb(beam=7)\n",
        "df_nllb_7['NLLB_7_Open_Subtitles'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab63bf18",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating:   2%|▏         | 1/62 [00:42<43:17, 42.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial translations: ['You see.', 'It made me laugh.', \"Let's fix him up and show him the best shot.\", \"Aren't you going to use your brain?\", 'Oh, my God.', 'Give it to me.', \"Let's get out of here.\", 'A self-proclaimed smart guy.', \"That's good.\", 'See you again.', 'Got it, you little assholes, get out of here.', \"Don't ever come back.\", \"Hey, what's going on?\", 'Hey, hold your hands, you... shoot him and keep planning the war.', 'Come on now.', 'Let me wait for you...']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating: 100%|██████████| 62/62 [45:30<00:00, 44.04s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cantonese</th>\n",
              "      <th>english</th>\n",
              "      <th>beam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>你看</td>\n",
              "      <td>Look.</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>笑死我了</td>\n",
              "      <td>- That kills me. -</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>來整蠱他吧,讓他見識最佳拍檔</td>\n",
              "      <td>Come on, we'll fix him. Let's give him the old...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>你還不會用腦嗎?</td>\n",
              "      <td>Won't you ever grow up?</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>喂喂</td>\n",
              "      <td>- What? - Yoo-hoo!</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        cantonese                                            english  beam\n",
              "0              你看                                              Look.  None\n",
              "1            笑死我了                                 - That kills me. -  None\n",
              "2  來整蠱他吧,讓他見識最佳拍檔  Come on, we'll fix him. Let's give him the old...  None\n",
              "3        你還不會用腦嗎?                            Won't you ever grow up?  None\n",
              "4              喂喂                                 - What? - Yoo-hoo!  None"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_nllb_10 = load_all_datasets(\"NLLB_10\")\n",
        "df_nllb_10['NLLB_10_Open_Subtitles']['beam'] = translate_nllb(beam=10)\n",
        "df_nllb_10['NLLB_10_Open_Subtitles'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "0a972828",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating:   2%|▏         | 1/62 [01:21<1:22:59, 81.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial translations: ['You see.', 'It made me laugh.', \"Let's get him cleaned up and show him the best shot.\", \"Aren't you going to use your brain?\", 'Oh, my God.', 'Give it to me.', 'Get out of the way, turn around.', 'A self-proclaimed smart guy.', \"That's good.\", 'See you again.', 'Got it, you little bastards, get out of here.', \"Don't ever come back.\", \"Hey, what's going on?\", 'Hey, hold your hands, you... shoot him and keep planning the war.', 'Come on now.', 'Let me wait for you...']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating: 100%|██████████| 62/62 [1:06:02<00:00, 63.91s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cantonese</th>\n",
              "      <th>english</th>\n",
              "      <th>beam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>你看</td>\n",
              "      <td>Look.</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>笑死我了</td>\n",
              "      <td>- That kills me. -</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>來整蠱他吧,讓他見識最佳拍檔</td>\n",
              "      <td>Come on, we'll fix him. Let's give him the old...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>你還不會用腦嗎?</td>\n",
              "      <td>Won't you ever grow up?</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>喂喂</td>\n",
              "      <td>- What? - Yoo-hoo!</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        cantonese                                            english  beam\n",
              "0              你看                                              Look.  None\n",
              "1            笑死我了                                 - That kills me. -  None\n",
              "2  來整蠱他吧,讓他見識最佳拍檔  Come on, we'll fix him. Let's give him the old...  None\n",
              "3        你還不會用腦嗎?                            Won't you ever grow up?  None\n",
              "4              喂喂                                 - What? - Yoo-hoo!  None"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_nllb_15 = load_all_datasets(\"NLLB_15\")\n",
        "df_nllb_15['NLLB_15_Open_Subtitles']['beam'] = translate_nllb(beam=15)\n",
        "df_nllb_15['NLLB_15_Open_Subtitles'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "2442d7b3",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating:   2%|▏         | 1/62 [00:35<36:22, 35.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial translations: ['You see.', 'It made me laugh.', \"Let's fix him up and show him the best shot.\", \"Aren't you going to use your brain?\", 'Oh, my God.', 'Give it to me.', \"Let's get out of here.\", 'A self-proclaimed smart guy.', \"That's good.\", 'See you again.', 'Got it, you little assholes, get out of here.', \"Don't ever come back.\", \"Hey, what's going on?\", 'Hey, hold your hands, you... shoot him and keep planning the war.', 'Come on now.', 'Let me wait for you...']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating: 100%|██████████| 62/62 [44:13<00:00, 42.80s/it]\n"
          ]
        }
      ],
      "source": [
        "df_nllb_10['NLLB_10_Open_Subtitles']['greedy'] = translate_nllb(beam=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c2898399",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             cantonese                                        english\n",
            "0              我要去瞓覺喇。                         I have to go to sleep.\n",
            "1  我話唔定做一陣就會放棄，走去瞓晏覺算。       I may give up soon and just nap instead.\n",
            "2       我不嬲都鍾意啲神秘啲嘅人物。     I always liked mysterious characters more.\n",
            "3   雖然佢講咗對唔住，但係我都仲係好嬲。  Even though he apologized, I'm still furious.\n",
            "4               我唯有係等。                               I can only wait.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating:   0%|          | 0/63 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:   2%|▏         | 1/63 [00:20<21:07, 20.45s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:   3%|▎         | 2/63 [00:38<19:17, 18.98s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:   5%|▍         | 3/63 [00:53<17:15, 17.26s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:   6%|▋         | 4/63 [01:04<14:36, 14.85s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:   8%|▊         | 5/63 [01:20<14:43, 15.23s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  10%|▉         | 6/63 [01:31<13:02, 13.73s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  11%|█         | 7/63 [01:42<11:55, 12.77s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  13%|█▎        | 8/63 [01:54<11:27, 12.50s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  14%|█▍        | 9/63 [02:04<10:43, 11.91s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  16%|█▌        | 10/63 [02:24<12:43, 14.41s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  17%|█▋        | 11/63 [02:36<11:38, 13.44s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  19%|█▉        | 12/63 [02:57<13:31, 15.90s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  21%|██        | 13/63 [03:11<12:48, 15.38s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  22%|██▏       | 14/63 [03:22<11:27, 14.04s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  24%|██▍       | 15/63 [03:40<12:13, 15.28s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  25%|██▌       | 16/63 [03:54<11:35, 14.79s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  27%|██▋       | 17/63 [04:08<11:08, 14.53s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  29%|██▊       | 18/63 [04:22<10:42, 14.29s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  30%|███       | 19/63 [04:31<09:21, 12.76s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  32%|███▏      | 20/63 [04:43<08:59, 12.55s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  33%|███▎      | 21/63 [04:59<09:32, 13.64s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  35%|███▍      | 22/63 [05:16<10:03, 14.72s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  37%|███▋      | 23/63 [05:29<09:20, 14.02s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  38%|███▊      | 24/63 [05:58<11:59, 18.46s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  40%|███▉      | 25/63 [06:30<14:21, 22.68s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  41%|████▏     | 26/63 [06:45<12:34, 20.39s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  43%|████▎     | 27/63 [07:02<11:31, 19.22s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  44%|████▍     | 28/63 [07:14<10:03, 17.25s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  46%|████▌     | 29/63 [07:24<08:30, 15.01s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  48%|████▊     | 30/63 [07:39<08:09, 14.85s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  49%|████▉     | 31/63 [07:49<07:10, 13.46s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  51%|█████     | 32/63 [08:02<06:59, 13.52s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  52%|█████▏    | 33/63 [08:11<05:57, 11.91s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  54%|█████▍    | 34/63 [08:24<05:55, 12.27s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  56%|█████▌    | 35/63 [08:40<06:19, 13.56s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  57%|█████▋    | 36/63 [08:50<05:35, 12.41s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  59%|█████▊    | 37/63 [08:59<04:54, 11.34s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  60%|██████    | 38/63 [09:13<05:04, 12.16s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  62%|██████▏   | 39/63 [09:27<05:04, 12.71s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  63%|██████▎   | 40/63 [09:44<05:19, 13.89s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  65%|██████▌   | 41/63 [09:55<04:47, 13.08s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  67%|██████▋   | 42/63 [10:06<04:26, 12.68s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  68%|██████▊   | 43/63 [10:42<06:30, 19.53s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  70%|██████▉   | 44/63 [11:00<06:04, 19.21s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  71%|███████▏  | 45/63 [11:13<05:08, 17.17s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  73%|███████▎  | 46/63 [11:23<04:14, 14.98s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  75%|███████▍  | 47/63 [11:38<04:01, 15.12s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  76%|███████▌  | 48/63 [11:47<03:17, 13.15s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  78%|███████▊  | 49/63 [11:56<02:46, 11.87s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  79%|███████▉  | 50/63 [12:02<02:11, 10.09s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  81%|████████  | 51/63 [12:16<02:18, 11.54s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  83%|████████▎ | 52/63 [12:35<02:29, 13.61s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  84%|████████▍ | 53/63 [12:45<02:04, 12.44s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  86%|████████▌ | 54/63 [12:56<01:49, 12.17s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  87%|████████▋ | 55/63 [13:03<01:23, 10.48s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  89%|████████▉ | 56/63 [13:15<01:17, 11.12s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  90%|█████████ | 57/63 [13:36<01:24, 14.05s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  92%|█████████▏| 58/63 [13:46<01:04, 12.81s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  94%|█████████▎| 59/63 [13:56<00:48, 12.01s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  95%|█████████▌| 60/63 [14:03<00:31, 10.46s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  97%|█████████▋| 61/63 [14:11<00:19,  9.55s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  98%|█████████▊| 62/63 [14:22<00:10, 10.03s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating: 100%|██████████| 63/63 [14:29<00:00, 13.81s/it]\n",
            "Translating: 100%|██████████| 63/63 [38:20<00:00, 36.51s/it] \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cantonese</th>\n",
              "      <th>english</th>\n",
              "      <th>greedy</th>\n",
              "      <th>beam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>我要去瞓覺喇。</td>\n",
              "      <td>I have to go to sleep.</td>\n",
              "      <td>Менің қазір мен қасымда.</td>\n",
              "      <td>Өзiмiкiнiгiпiң кiлiшiрi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>我話唔定做一陣就會放棄，走去瞓晏覺算。</td>\n",
              "      <td>I may give up soon and just nap instead.</td>\n",
              "      <td>Менің қазір, қаңтар мен қазыққа қазанды, менің...</td>\n",
              "      <td>Қандай-ақ, қанақтар мен ұзақ уақытқа дейін қар...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>我不嬲都鍾意啲神秘啲嘅人物。</td>\n",
              "      <td>I always liked mysterious characters more.</td>\n",
              "      <td>Менің табылған тазалық тазыққа не айтылады.</td>\n",
              "      <td>Je n’ai pas l’intention de connaître les perso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>雖然佢講咗對唔住，但係我都仲係好嬲。</td>\n",
              "      <td>Even though he apologized, I'm still furious.</td>\n",
              "      <td>Менің қазір мен қаңтар менің жарыққа қадам.</td>\n",
              "      <td>Қандай-ақ, қазір мен қағидалар мен жарықтармен...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>我唯有係等。</td>\n",
              "      <td>I can only wait.</td>\n",
              "      <td>Менің қазір мен қасым.</td>\n",
              "      <td>Je n’ai qu’à attendre.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             cantonese                                        english  \\\n",
              "0              我要去瞓覺喇。                         I have to go to sleep.   \n",
              "1  我話唔定做一陣就會放棄，走去瞓晏覺算。       I may give up soon and just nap instead.   \n",
              "2       我不嬲都鍾意啲神秘啲嘅人物。     I always liked mysterious characters more.   \n",
              "3   雖然佢講咗對唔住，但係我都仲係好嬲。  Even though he apologized, I'm still furious.   \n",
              "4               我唯有係等。                               I can only wait.   \n",
              "\n",
              "                                              greedy  \\\n",
              "0                           Менің қазір мен қасымда.   \n",
              "1  Менің қазір, қаңтар мен қазыққа қазанды, менің...   \n",
              "2        Менің табылған тазалық тазыққа не айтылады.   \n",
              "3        Менің қазір мен қаңтар менің жарыққа қадам.   \n",
              "4                             Менің қазір мен қасым.   \n",
              "\n",
              "                                                beam  \n",
              "0                           Өзiмiкiнiгiпiң кiлiшiрi.  \n",
              "1  Қандай-ақ, қанақтар мен ұзақ уақытқа дейін қар...  \n",
              "2  Je n’ai pas l’intention de connaître les perso...  \n",
              "3  Қандай-ақ, қазір мен қағидалар мен жарықтармен...  \n",
              "4                             Je n’ai qu’à attendre.  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run using M2M\n",
        "df_m2m = load_parallel_corpus('en-yue.txt/Tatoeba.en-yue.yue', 'en-yue.txt/Tatoeba.en-yue.en', max_lines=1000)\n",
        "print(df_m2m.head())\n",
        "\n",
        "df_m2m['greedy'] = translate_select_model(df_m2m['cantonese'].tolist(), tokenizer_m2m, model_m2m, beam=1, batch_size=16, device=device)\n",
        "df_m2m['beam'] = translate_select_model(df_m2m['cantonese'].tolist(), tokenizer_m2m, model_m2m, beam=5, batch_size=16, device=device)\n",
        "df_m2m.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "0b3168f1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             cantonese                                        english\n",
            "0              我要去瞓覺喇。                         I have to go to sleep.\n",
            "1  我話唔定做一陣就會放棄，走去瞓晏覺算。       I may give up soon and just nap instead.\n",
            "2       我不嬲都鍾意啲神秘啲嘅人物。     I always liked mysterious characters more.\n",
            "3   雖然佢講咗對唔住，但係我都仲係好嬲。  Even though he apologized, I'm still furious.\n",
            "4               我唯有係等。                               I can only wait.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating:   2%|▏         | 1/63 [00:11<11:49, 11.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial translations: ['I have to go to bed.', 'I said, \"I\\'m going to give up and go to bed\".', 'I like mysterious characters.', 'She apologized, but I was still a little bit of a bitch.', 'I was just waiting.', 'I love you.', 'It will land on the moon tomorrow.', \"It'll land on the moon tomorrow.\", '\"Honestly, I\\'m scared of being high\". \"No more cowards!\"', '\"The phone rings\". \"I hear you\".', '\"Thank you for your help\". \"No, thank you\".', '\"What are you doing wrong?\" \"Because I don\\'t want to go to the bathroom\".', \"Democracy is the worst political system, except for the ones we've tried.\", \"Oh, that's good to see you!\", 'Can you speak Italian?', 'Do you have a condom?']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating: 100%|██████████| 63/63 [07:14<00:00,  6.89s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cantonese</th>\n",
              "      <th>english</th>\n",
              "      <th>greedy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>我要去瞓覺喇。</td>\n",
              "      <td>I have to go to sleep.</td>\n",
              "      <td>I have to go to bed.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>我話唔定做一陣就會放棄，走去瞓晏覺算。</td>\n",
              "      <td>I may give up soon and just nap instead.</td>\n",
              "      <td>I said, \"I'm going to give up and go to bed\".</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>我不嬲都鍾意啲神秘啲嘅人物。</td>\n",
              "      <td>I always liked mysterious characters more.</td>\n",
              "      <td>I like mysterious characters.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>雖然佢講咗對唔住，但係我都仲係好嬲。</td>\n",
              "      <td>Even though he apologized, I'm still furious.</td>\n",
              "      <td>She apologized, but I was still a little bit o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>我唯有係等。</td>\n",
              "      <td>I can only wait.</td>\n",
              "      <td>I was just waiting.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             cantonese                                        english  \\\n",
              "0              我要去瞓覺喇。                         I have to go to sleep.   \n",
              "1  我話唔定做一陣就會放棄，走去瞓晏覺算。       I may give up soon and just nap instead.   \n",
              "2       我不嬲都鍾意啲神秘啲嘅人物。     I always liked mysterious characters more.   \n",
              "3   雖然佢講咗對唔住，但係我都仲係好嬲。  Even though he apologized, I'm still furious.   \n",
              "4               我唯有係等。                               I can only wait.   \n",
              "\n",
              "                                              greedy  \n",
              "0                               I have to go to bed.  \n",
              "1      I said, \"I'm going to give up and go to bed\".  \n",
              "2                      I like mysterious characters.  \n",
              "3  She apologized, but I was still a little bit o...  \n",
              "4                                I was just waiting.  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run using M2M\n",
        "df_nllb = load_parallel_corpus('en-yue.txt/Tatoeba.en-yue.yue', 'en-yue.txt/Tatoeba.en-yue.en', max_lines=1000)\n",
        "print(df_nllb.head())\n",
        "\n",
        "df_nllb['greedy'] = translate_select_model(df_nllb['cantonese'].tolist(), tokenizer_nllb, model_nllb, beam=1, batch_size=16, device=device, src_lang=\"yue_Hant\", tgt_lang= \"eng_Latn\")\n",
        "df_nllb.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "fad2d1fa",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating:   2%|▏         | 1/63 [00:27<28:20, 27.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial translations: ['I have to go to bed.', \"I told him I'd give up and go to bed.\", 'I like more mysterious characters.', 'She apologized, but I was fine.', 'I was just waiting.', 'I love you.', 'It will land on the moon tomorrow.', 'It will land on the moon tomorrow.', '\"Honestly, I\\'m really scared\". \"Don\\'t be a coward!\"', '\"The phone rings\". \"I hear you\".', '\"Thank you very much\". \"No, thank you\".', '\"What are you not doing?\" \"Because I don\\'t want to go\".', \"Democracy is the worst political system I've ever tried.\", 'Oh, good to see you!', 'Can you speak Italian?', 'Do you have a condom?']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating: 100%|██████████| 63/63 [25:26<00:00, 24.22s/it]\n"
          ]
        }
      ],
      "source": [
        "df_nllb['beam'] = translate_select_model(df_nllb['cantonese'].tolist(), tokenizer_nllb, model_nllb, beam=5, batch_size=16, device=device, src_lang=\"yue_Hant\", tgt_lang=\"eng_Latn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "2c2b4c22",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        cantonese                                            english\n",
            "0              你看                                              Look.\n",
            "1            笑死我了                                 - That kills me. -\n",
            "2  來整蠱他吧,讓他見識最佳拍檔  Come on, we'll fix him. Let's give him the old...\n",
            "3        你還不會用腦嗎?                            Won't you ever grow up?\n",
            "4              喂喂                                 - What? - Yoo-hoo!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating:   2%|▏         | 1/62 [00:05<05:12,  5.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial translations: ['You see.', 'It made me laugh.', 'Get him a job and let him see the best shot.', \"You're not going to use your brain?\", 'Oh, my God.', 'Give me a round.', 'Go ahead and roll.', 'A self-righteous asshole.', \"That's good.\", 'See you again.', 'Get it, you little bastards, get out of here.', 'Never come back.', 'What are we doing?', 'Hold your hands, you... shoot him and keep planning the war.', 'Come on, you know.', 'Let me wait for you...']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating: 100%|██████████| 62/62 [07:05<00:00,  6.87s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cantonese</th>\n",
              "      <th>english</th>\n",
              "      <th>greedy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>你看</td>\n",
              "      <td>Look.</td>\n",
              "      <td>You see.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>笑死我了</td>\n",
              "      <td>- That kills me. -</td>\n",
              "      <td>It made me laugh.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>來整蠱他吧,讓他見識最佳拍檔</td>\n",
              "      <td>Come on, we'll fix him. Let's give him the old...</td>\n",
              "      <td>Get him a job and let him see the best shot.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>你還不會用腦嗎?</td>\n",
              "      <td>Won't you ever grow up?</td>\n",
              "      <td>You're not going to use your brain?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>喂喂</td>\n",
              "      <td>- What? - Yoo-hoo!</td>\n",
              "      <td>Oh, my God.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        cantonese                                            english  \\\n",
              "0              你看                                              Look.   \n",
              "1            笑死我了                                 - That kills me. -   \n",
              "2  來整蠱他吧,讓他見識最佳拍檔  Come on, we'll fix him. Let's give him the old...   \n",
              "3        你還不會用腦嗎?                            Won't you ever grow up?   \n",
              "4              喂喂                                 - What? - Yoo-hoo!   \n",
              "\n",
              "                                         greedy  \n",
              "0                                      You see.  \n",
              "1                             It made me laugh.  \n",
              "2  Get him a job and let him see the best shot.  \n",
              "3           You're not going to use your brain?  \n",
              "4                                   Oh, my God.  "
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run using M2M\n",
        "df_nllb_os = load_parallel_corpus('open-subtitles_en-yue.txt/OpenSubtitles.en-yue.yue', 'open-subtitles_en-yue.txt/OpenSubtitles.en-yue.en', max_lines=1000)\n",
        "print(df_nllb_os.head())\n",
        "\n",
        "df_nllb_os['greedy'] = translate_select_model(df_nllb_os['cantonese'].tolist(), tokenizer_nllb, model_nllb, beam=1, batch_size=16, device=device, src_lang=\"yue_Hant\", tgt_lang= \"eng_Latn\")\n",
        "df_nllb_os.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "aa98c926",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating:   2%|▏         | 1/62 [00:23<23:44, 23.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial translations: ['You see.', 'It made me laugh.', \"Let's fix him up and show him the best shot.\", \"Aren't you going to use your brain?\", 'Oh, my God.', 'Give it to me.', 'Get out of the way.', 'A self-righteous asshole.', \"That's good.\", 'See you again.', 'Get it, you little assholes, get out of here.', \"Don't ever come back.\", \"Hey, what's going on?\", 'Okay, hold your hands, you... shoot him, and continue the war plan.', 'Come on now.', 'Let me wait for you...']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating: 100%|██████████| 62/62 [27:16<00:00, 26.39s/it]\n"
          ]
        }
      ],
      "source": [
        "# run beam search using nllb model on Open Subtitles dataset\n",
        "df_nllb_os['beam'] = translate_select_model(df_nllb_os['cantonese'].tolist(), tokenizer_nllb, model_nllb, beam=5, batch_size=16, device=device, src_lang=\"yue_Hant\", tgt_lang=\"eng_Latn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "5d20159d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sacrebleu import corpus_bleu\n",
        "from sacrebleu import corpus_chrf\n",
        "\n",
        "# Function to loop over all  dataframes defined and print out BLEU and CHRF scores\n",
        "def compute_scores(df, name=\"\", use_greedy=True, use_beam=True):\n",
        "    greedy_bleu, greedy_chrf, beam_bleu, beam_chrf = None, None, None, None\n",
        "    references = [df['english'].astype(str).tolist()]\n",
        "\n",
        "    if use_greedy:\n",
        "        # Prepare hypothesis and reference lists\n",
        "        greedy_hypotheses = df['greedy'].astype(str).tolist()\n",
        "        # Compute BLEU scores\n",
        "        greedy_bleu = corpus_bleu(greedy_hypotheses, references).score\n",
        "        greedy_chrf = corpus_chrf(greedy_hypotheses, references).score\n",
        "\n",
        "    if use_beam:\n",
        "        beam_hypotheses = df['beam'].astype(str).tolist()\n",
        "        beam_bleu = corpus_bleu(beam_hypotheses, references).score\n",
        "        beam_chrf = corpus_chrf(beam_hypotheses, references).score\n",
        "\n",
        "    # Print results\n",
        "    print(f\"{name} BLEU Scores:\")\n",
        "    if use_greedy:\n",
        "        print(f\"Greedy BLEU: {greedy_bleu:.2f}\")\n",
        "    if use_beam:\n",
        "        print(f\"Beam BLEU:   {beam_bleu:.2f}\")\n",
        "    \n",
        "    print(f\"\\n{name} CHRF Scores:\")\n",
        "    if use_greedy:\n",
        "        print(f\"Greedy CHRF: {greedy_chrf:.2f}\")\n",
        "    if use_beam:\n",
        "        print(f\"BEAM CHRF: {beam_chrf:.2f}\")\n",
        "    \n",
        "    return greedy_bleu, beam_bleu, greedy_chrf, beam_chrf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e3d34183",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating name: m2m\n",
            "\n",
            "m2m BLEU Scores:\n",
            "Greedy BLEU: 0.07\n",
            "Beam BLEU:   0.07\n",
            "\n",
            "m2m CHRF Scores:\n",
            "Greedy CHRF: 3.96\n",
            "BEAM CHRF: 5.22\n"
          ]
        }
      ],
      "source": [
        "results_m2m = {}\n",
        "name = \"m2m\"\n",
        "print(f\"Evaluating name: {name}\")\n",
        "greedy_bleu, beam_bleu, greedy_chrf, beam_chrf = compute_scores(df_m2m, name)\n",
        "results_m2m[name] = {\"greedy_bleu\": greedy_bleu, \"beam_bleu\": beam_bleu, \"greedy_chrf\": greedy_chrf, \"beam_chrf\": beam_chrf}\n",
        "df_m2m.to_csv(f\"trans_res_{name}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0027b2b9",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating:   0%|          | 0/62 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:   2%|▏         | 1/62 [01:03<1:04:14, 63.18s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:   3%|▎         | 2/62 [01:09<29:51, 29.87s/it]  The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:   5%|▍         | 3/62 [01:21<21:05, 21.46s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:   6%|▋         | 4/62 [01:28<15:25, 15.96s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:   8%|▊         | 5/62 [01:39<13:13, 13.93s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  10%|▉         | 6/62 [01:50<12:04, 12.94s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  11%|█▏        | 7/62 [02:02<11:37, 12.69s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  13%|█▎        | 8/62 [02:13<11:08, 12.39s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  15%|█▍        | 9/62 [02:25<10:41, 12.09s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  16%|█▌        | 10/62 [02:33<09:30, 10.97s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  18%|█▊        | 11/62 [02:46<09:47, 11.52s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  19%|█▉        | 12/62 [02:54<08:45, 10.51s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  21%|██        | 13/62 [03:00<07:23,  9.06s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  23%|██▎       | 14/62 [03:09<07:19,  9.15s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  24%|██▍       | 15/62 [03:21<07:42,  9.84s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  26%|██▌       | 16/62 [03:38<09:20, 12.18s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  27%|██▋       | 17/62 [03:44<07:39, 10.22s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  29%|██▉       | 18/62 [03:58<08:17, 11.30s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  31%|███       | 19/62 [04:09<08:00, 11.17s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  32%|███▏      | 20/62 [04:16<06:57,  9.95s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  34%|███▍      | 21/62 [04:24<06:25,  9.40s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  35%|███▌      | 22/62 [04:34<06:24,  9.62s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  37%|███▋      | 23/62 [04:43<06:02,  9.30s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  39%|███▊      | 24/62 [04:58<06:58, 11.02s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  40%|████      | 25/62 [05:05<06:02,  9.81s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  42%|████▏     | 26/62 [05:12<05:24,  9.02s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  44%|████▎     | 27/62 [05:21<05:16,  9.04s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  45%|████▌     | 28/62 [05:28<04:47,  8.46s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  47%|████▋     | 29/62 [05:35<04:20,  7.91s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  48%|████▊     | 30/62 [05:44<04:29,  8.41s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  50%|█████     | 31/62 [05:49<03:44,  7.24s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  52%|█████▏    | 32/62 [05:59<04:03,  8.12s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  53%|█████▎    | 33/62 [06:07<03:54,  8.08s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  55%|█████▍    | 34/62 [06:14<03:38,  7.81s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  56%|█████▋    | 35/62 [06:24<03:46,  8.41s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  58%|█████▊    | 36/62 [06:33<03:46,  8.71s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  60%|█████▉    | 37/62 [06:40<03:19,  7.98s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  61%|██████▏   | 38/62 [06:44<02:48,  7.00s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  63%|██████▎   | 39/62 [06:51<02:40,  6.99s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  65%|██████▍   | 40/62 [06:58<02:34,  7.04s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  66%|██████▌   | 41/62 [07:07<02:37,  7.51s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  68%|██████▊   | 42/62 [07:16<02:36,  7.83s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  69%|██████▉   | 43/62 [07:21<02:12,  7.00s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  71%|███████   | 44/62 [07:28<02:07,  7.10s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  73%|███████▎  | 45/62 [07:34<01:52,  6.61s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  74%|███████▍  | 46/62 [07:40<01:43,  6.48s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  76%|███████▌  | 47/62 [07:47<01:40,  6.72s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  77%|███████▋  | 48/62 [07:54<01:37,  6.95s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  79%|███████▉  | 49/62 [08:01<01:28,  6.83s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  81%|████████  | 50/62 [08:07<01:19,  6.61s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  82%|████████▏ | 51/62 [08:16<01:18,  7.17s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  84%|████████▍ | 52/62 [08:21<01:06,  6.70s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  85%|████████▌ | 53/62 [08:30<01:04,  7.18s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  87%|████████▋ | 54/62 [08:41<01:07,  8.40s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  89%|████████▊ | 55/62 [08:47<00:53,  7.70s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  90%|█████████ | 56/62 [08:55<00:47,  7.97s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  92%|█████████▏| 57/62 [09:33<01:24, 16.81s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  94%|█████████▎| 58/62 [09:43<00:58, 14.67s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  95%|█████████▌| 59/62 [09:52<00:39, 13.01s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  97%|█████████▋| 60/62 [09:59<00:22, 11.16s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating:  98%|█████████▊| 61/62 [10:07<00:10, 10.39s/it]The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Translating: 100%|██████████| 62/62 [10:12<00:00,  9.88s/it]\n",
            "Translating:   0%|          | 0/62 [00:12<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run using M2M on OpenSubtitles dataset\u001b[39;00m\n\u001b[32m      2\u001b[39m df_Open_Subtitles[\u001b[33m'\u001b[39m\u001b[33mgreedy\u001b[39m\u001b[33m'\u001b[39m] = translate_select_model(df_Open_Subtitles[\u001b[33m'\u001b[39m\u001b[33mcantonese\u001b[39m\u001b[33m'\u001b[39m].tolist(), tokenizer_m2m, model_m2m, beam=\u001b[32m1\u001b[39m, batch_size=\u001b[32m16\u001b[39m, device=device)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df_Open_Subtitles[\u001b[33m'\u001b[39m\u001b[33mbeam\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mtranslate_select_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_Open_Subtitles\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcantonese\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_m2m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_m2m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mtranslate_select_model\u001b[39m\u001b[34m(texts, tokenizer, model, beam, batch_size, device)\u001b[39m\n\u001b[32m     30\u001b[39m inputs = tokenizer(batch, padding=\u001b[38;5;28;01mTrue\u001b[39;00m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m, max_length=\u001b[32m128\u001b[39m, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(device)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     generated_tokens = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m batch_translations = tokenizer.batch_decode(generated_tokens, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     39\u001b[39m translations.extend(batch_translations)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Florence\\Homework\\UniversityOfWaterloo\\FourthYear\\CS486\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Florence\\Homework\\UniversityOfWaterloo\\FourthYear\\CS486\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2652\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2645\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2646\u001b[39m         input_ids=input_ids,\n\u001b[32m   2647\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2648\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2649\u001b[39m         **model_kwargs,\n\u001b[32m   2650\u001b[39m     )\n\u001b[32m   2651\u001b[39m     \u001b[38;5;66;03m# 12. run beam sample\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2652\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2657\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2658\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2659\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2661\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode == GenerationMode.GROUP_BEAM_SEARCH:\n\u001b[32m   2662\u001b[39m     logger.warning_once(\n\u001b[32m   2663\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGroup Beam Search is scheduled to be moved to a `custom_generate` repository in v4.55.0. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2664\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo prevent loss of backward compatibility, add `trust_remote_code=True` to your `generate` call.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2665\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Florence\\Homework\\UniversityOfWaterloo\\FourthYear\\CS486\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:4097\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   4094\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_attentions\u001b[39m\u001b[33m\"\u001b[39m: output_attentions} \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m   4095\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_hidden_states\u001b[39m\u001b[33m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m-> \u001b[39m\u001b[32m4097\u001b[39m model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   4099\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   4100\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   4101\u001b[39m     model_outputs,\n\u001b[32m   4102\u001b[39m     model_kwargs,\n\u001b[32m   4103\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   4104\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Florence\\Homework\\UniversityOfWaterloo\\FourthYear\\CS486\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Florence\\Homework\\UniversityOfWaterloo\\FourthYear\\CS486\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Florence\\Homework\\UniversityOfWaterloo\\FourthYear\\CS486\\.venv\\Lib\\site-packages\\transformers\\models\\m2m_100\\modeling_m2m_100.py:1422\u001b[39m, in \u001b[36mM2M100ForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1400\u001b[39m         decoder_input_ids = shift_tokens_right(\n\u001b[32m   1401\u001b[39m             labels, \u001b[38;5;28mself\u001b[39m.config.pad_token_id, \u001b[38;5;28mself\u001b[39m.config.decoder_start_token_id\n\u001b[32m   1402\u001b[39m         )\n\u001b[32m   1404\u001b[39m outputs = \u001b[38;5;28mself\u001b[39m.model(\n\u001b[32m   1405\u001b[39m     input_ids,\n\u001b[32m   1406\u001b[39m     attention_mask=attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1420\u001b[39m     cache_position=cache_position,\n\u001b[32m   1421\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m lm_logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1424\u001b[39m masked_lm_loss = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1425\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1426\u001b[39m     \u001b[38;5;66;03m# move labels to the correct device to enable PP\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Florence\\Homework\\UniversityOfWaterloo\\FourthYear\\CS486\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Florence\\Homework\\UniversityOfWaterloo\\FourthYear\\CS486\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Florence\\Homework\\UniversityOfWaterloo\\FourthYear\\CS486\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Run using M2M on OpenSubtitles dataset\n",
        "df_Open_Subtitles['greedy'] = translate_select_model(df_Open_Subtitles['cantonese'].tolist(), tokenizer_m2m, model_m2m, beam=1, batch_size=16, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b4e3ef57",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'yue'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_Open_Subtitles[\u001b[33m'\u001b[39m\u001b[33mbeam\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mtranslate_select_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_Open_Subtitles\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcantonese\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_m2m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_m2m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtranslate_select_model\u001b[39m\u001b[34m(texts, tokenizer, model, beam, batch_size, device)\u001b[39m\n\u001b[32m     25\u001b[39m model.to(device)\n\u001b[32m     26\u001b[39m model.eval()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msrc_lang\u001b[49m = \u001b[33m\"\u001b[39m\u001b[33myue\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# set source language to cantonese\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts), batch_size), desc=\u001b[33m\"\u001b[39m\u001b[33mTranslating\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     31\u001b[39m     batch = texts[i:i+batch_size]\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Florence\\Homework\\UniversityOfWaterloo\\FourthYear\\CS486\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1075\u001b[39m, in \u001b[36mSpecialTokensMixin.__setattr__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   1073\u001b[39m     \u001b[38;5;28mself\u001b[39m._special_tokens_map[key] = value\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Florence\\Homework\\UniversityOfWaterloo\\FourthYear\\CS486\\.venv\\Lib\\site-packages\\transformers\\models\\m2m_100\\tokenization_m2m_100.py:194\u001b[39m, in \u001b[36mM2M100Tokenizer.src_lang\u001b[39m\u001b[34m(self, new_src_lang)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;129m@src_lang\u001b[39m.setter\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msrc_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, new_src_lang: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    193\u001b[39m     \u001b[38;5;28mself\u001b[39m._src_lang = new_src_lang\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mset_src_lang_special_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_src_lang\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Florence\\Homework\\UniversityOfWaterloo\\FourthYear\\CS486\\.venv\\Lib\\site-packages\\transformers\\models\\m2m_100\\tokenization_m2m_100.py:348\u001b[39m, in \u001b[36mM2M100Tokenizer.set_src_lang_special_tokens\u001b[39m\u001b[34m(self, src_lang)\u001b[39m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_src_lang_special_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m, src_lang: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    347\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Reset the special tokens to the source lang setting. No prefix and suffix=[eos, src_lang_code].\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     lang_token = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_lang_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_lang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m.cur_lang_id = \u001b[38;5;28mself\u001b[39m.lang_token_to_id[lang_token]\n\u001b[32m    350\u001b[39m     \u001b[38;5;28mself\u001b[39m.prefix_tokens = [\u001b[38;5;28mself\u001b[39m.cur_lang_id]\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Florence\\Homework\\UniversityOfWaterloo\\FourthYear\\CS486\\.venv\\Lib\\site-packages\\transformers\\models\\m2m_100\\tokenization_m2m_100.py:361\u001b[39m, in \u001b[36mM2M100Tokenizer.get_lang_token\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_lang_token\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlang_code_to_token\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m]\u001b[49m\n",
            "\u001b[31mKeyError\u001b[39m: 'yue'"
          ]
        }
      ],
      "source": [
        "df_Open_Subtitles['beam'] = translate_select_model(df_Open_Subtitles['cantonese'].tolist(), tokenizer_m2m, model_m2m, beam=5, batch_size=16, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "019283b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "m2m BLEU Scores:\n",
            "Greedy BLEU: 0.56\n",
            "\n",
            "m2m CHRF Scores:\n",
            "Greedy CHRF: 10.44\n"
          ]
        }
      ],
      "source": [
        "greedy_bleu, beam_bleu, greedy_chrf, beam_chrf = compute_scores(df=df_Open_Subtitles, name=name, use_beam=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c9e89a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run translations for greedy and beam search algorithm using OpenSubtitles dataset\n",
        "df_OS_mBART = load_parallel_corpus('open-subtitles_en-yue.txt/OpenSubtitles.en-yue.yue', 'open-subtitles_en-yue.txt/OpenSubtitles.en-yue.en', max_lines=1000)\n",
        "print(df_OS_mBART.head())\n",
        "df_OS_mBART['greedy'] = translate(df_OS_mBART['cantonese'].tolist(), beam=1, batch_size=16)\n",
        "df_OS_mBART['beam'] = translate(df_OS_mBART['cantonese'].tolist(), beam=5, batch_size=16)\n",
        "df_OS_mBART.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b1f3015",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Run using MarianMT on Tatoeba dataset\n",
        "# df_Tatoeba = load_parallel_corpus('en-yue.txt/Tatoeba.en-yue.yue', 'en-yue.txt/Tatoeba.en-yue.en', max_lines=1000)\n",
        "# print(df_Tatoeba.head())\n",
        "\n",
        "# df_Tatoeba['greedy'] = translate(df_Tatoeba['cantonese'].tolist(), tokenizer_mar, model_mar, beam=1, batch_size=16, device=device)\n",
        "# df_Tatoeba['beam'] = translate(df_Tatoeba['cantonese'].tolist(), tokenizer_mar, model_mar, beam=5, batch_size=16, device=device)\n",
        "# df_Tatoeba.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64dc650a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        cantonese                                            english\n",
            "0              你看                                              Look.\n",
            "1            笑死我了                                 - That kills me. -\n",
            "2  來整蠱他吧,讓他見識最佳拍檔  Come on, we'll fix him. Let's give him the old...\n",
            "3        你還不會用腦嗎?                            Won't you ever grow up?\n",
            "4              喂喂                                 - What? - Yoo-hoo!\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'tokenizer_mar' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m df_OS_Mar = load_parallel_corpus(\u001b[33m'\u001b[39m\u001b[33mopen-subtitles_en-yue.txt/OpenSubtitles.en-yue.yue\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mopen-subtitles_en-yue.txt/OpenSubtitles.en-yue.en\u001b[39m\u001b[33m'\u001b[39m, max_lines=\u001b[32m1000\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_OS_Mar.head())\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df_OS_Mar[\u001b[33m'\u001b[39m\u001b[33mgreedy\u001b[39m\u001b[33m'\u001b[39m] = translate(df_OS_Mar[\u001b[33m'\u001b[39m\u001b[33mcantonese\u001b[39m\u001b[33m'\u001b[39m].tolist(), \u001b[43mtokenizer_mar\u001b[49m, model_mar, beam=\u001b[32m1\u001b[39m, batch_size=\u001b[32m16\u001b[39m, device=device)\n\u001b[32m      6\u001b[39m df_OS_Mar[\u001b[33m'\u001b[39m\u001b[33mbeam\u001b[39m\u001b[33m'\u001b[39m] = translate(df_OS_Mar[\u001b[33m'\u001b[39m\u001b[33mcantonese\u001b[39m\u001b[33m'\u001b[39m].tolist(), tokenizer_mar, model_mar, beam=\u001b[32m5\u001b[39m, batch_size=\u001b[32m16\u001b[39m, device=device)\n",
            "\u001b[31mNameError\u001b[39m: name 'tokenizer_mar' is not defined"
          ]
        }
      ],
      "source": [
        "# Run using MarianMT on OpenSubtitles dataset\n",
        "df_OS_Mar = load_parallel_corpus('open-subtitles_en-yue.txt/OpenSubtitles.en-yue.yue', 'open-subtitles_en-yue.txt/OpenSubtitles.en-yue.en', max_lines=1000)\n",
        "print(df_OS_Mar.head())\n",
        "\n",
        "df_OS_Mar['greedy'] = translate(df_OS_Mar['cantonese'].tolist(), tokenizer_mar, model_mar, beam=1, batch_size=16, device=device)\n",
        "df_OS_Mar['beam'] = translate(df_OS_Mar['cantonese'].tolist(), tokenizer_mar, model_mar, beam=5, batch_size=16, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74fb8ffb",
      "metadata": {},
      "source": [
        "## Evaluate algorithms using BLEU scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "107a9cb9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greedy BLEU: 7.94\n",
            "Beam BLEU: 9.21\n"
          ]
        }
      ],
      "source": [
        "from sacrebleu import corpus_bleu\n",
        "\n",
        "# Define hypotheses for greedy and beam search (as string lists)\n",
        "greedy_hypotheses = df['greedy'].astype(str).tolist()\n",
        "beam_hypotheses = df['beam'].astype(str).tolist()\n",
        "\n",
        "# Define references as string lists\n",
        "references = [df['english'].astype(str).tolist()]\n",
        "\n",
        "# Calculate the bleu score\n",
        "greedy_bleu = corpus_bleu(greedy_hypotheses, references).score\n",
        "beam_bleu = corpus_bleu(beam_hypotheses, references).score\n",
        "\n",
        "# Display bleu score\n",
        "print(f\"Greedy BLEU: {greedy_bleu:.2f}\")\n",
        "print(f\"Beam BLEU: {beam_bleu:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "684d22c4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating name: Tatoeba_NLLB, True\n",
            "Tatoeba_NLLB BLEU Scores:\n",
            "Greedy BLEU: 24.62\n",
            "Beam BLEU:   24.79\n",
            "\n",
            "Tatoeba_NLLB CHRF Scores:\n",
            "Greedy CHRF: 43.91\n",
            "BEAM CHRF: 44.18\n",
            "-------\n",
            "Evaluating name: OpenSubtitles_NLLB, True\n",
            "OpenSubtitles_NLLB BLEU Scores:\n",
            "Greedy BLEU: 14.80\n",
            "Beam BLEU:   15.54\n",
            "\n",
            "OpenSubtitles_NLLB CHRF Scores:\n",
            "Greedy CHRF: 34.10\n",
            "BEAM CHRF: 34.75\n",
            "-------\n",
            "Evaluating name: NLLB_7_Open_Subtitles, False\n",
            "NLLB_7_Open_Subtitles BLEU Scores:\n",
            "Beam BLEU:   0.00\n",
            "\n",
            "NLLB_7_Open_Subtitles CHRF Scores:\n",
            "BEAM CHRF: 2.95\n",
            "-------\n",
            "Evaluating name: Tatoeba_m2m, True\n",
            "Tatoeba_m2m BLEU Scores:\n",
            "Greedy BLEU: 0.07\n",
            "Beam BLEU:   0.07\n",
            "\n",
            "Tatoeba_m2m CHRF Scores:\n",
            "Greedy CHRF: 3.96\n",
            "BEAM CHRF: 5.22\n",
            "-------\n",
            "Evaluating name: OpenSubtitles_m2m, True\n",
            "Error evaluating OpenSubtitles_m2m: 'beam'\n",
            "Evaluating name: NLLB_3_Tatoeba, False\n",
            "NLLB_3_Tatoeba BLEU Scores:\n",
            "Beam BLEU:   0.00\n",
            "\n",
            "NLLB_3_Tatoeba CHRF Scores:\n",
            "BEAM CHRF: 3.04\n",
            "-------\n",
            "Evaluating name: NLLB_3_Open_Subtitles, False\n",
            "NLLB_3_Open_Subtitles BLEU Scores:\n",
            "Beam BLEU:   0.00\n",
            "\n",
            "NLLB_3_Open_Subtitles CHRF Scores:\n",
            "BEAM CHRF: 2.95\n",
            "-------\n",
            "Evaluating name: NLLB_15_Tatoeba, False\n",
            "Error evaluating NLLB_15_Tatoeba: 'beam'\n",
            "Evaluating name: NLLB_15_Open_Subtitles, False\n",
            "NLLB_15_Open_Subtitles BLEU Scores:\n",
            "Beam BLEU:   0.00\n",
            "\n",
            "NLLB_15_Open_Subtitles CHRF Scores:\n",
            "BEAM CHRF: 2.95\n",
            "-------\n"
          ]
        }
      ],
      "source": [
        "# Define a list of (name, dataframe) pairs\n",
        "use_beam = True\n",
        "use_greedy = True\n",
        "dataframes = [\n",
        "    # (\"Tatoeba + mBART\", df),\n",
        "    # (\"Open Subtitles_mBART\", df_OS_mBART),\n",
        "    (\"Tatoeba_NLLB\", df_nllb, use_greedy ), # beam = 5, greedy = 1\n",
        "    (\"OpenSubtitles_NLLB\", df_nllb_os, use_greedy), # beam = 5, greedy = 1\n",
        "    (\"NLLB_7_Open_Subtitles\", df_nllb_7['NLLB_7_Open_Subtitles'], False), # beam = 7\n",
        "    (\"Tatoeba_m2m\", df_m2m, use_greedy), # beam = n/a\n",
        "    (\"OpenSubtitles_m2m\", df_Open_Subtitles, use_greedy), # n/a\n",
        "    (\"NLLB_3_Tatoeba\", df_nllb_3['NLLB_3_Tatoeba'], False), # n/a\n",
        "    (\"NLLB_3_Open_Subtitles\", df_nllb_3['NLLB_3_Open_Subtitles'], False), # beam = 3\n",
        "    (\"NLLB_15_Tatoeba\", df_nllb_15['NLLB_15_Tatoeba'], False), # n/a\n",
        "    (\"NLLB_15_Open_Subtitles\", df_nllb_15['NLLB_15_Open_Subtitles'], False), # beam = 15\n",
        "    # (\"NLLB_7_Tatoeba\", df_nllb_7['NLLB_7_Open_Tatoeba']),\n",
        "    \n",
        "]\n",
        "\n",
        "\n",
        "# Compute BLEU and CHRF scores for each DataFrame\n",
        "results = {}\n",
        "scores = {\n",
        "    \"beam_size\": [],\n",
        "    \"BLEU\": [],\n",
        "    \"chrf\": []\n",
        "}\n",
        "\n",
        "# Calculate BLEU and CHRF scores for each of the data frames and save to list\n",
        "for name, df_, use_greedy in dataframes:\n",
        "    try:\n",
        "        print(f\"Evaluating name: {name}, {use_greedy}\")\n",
        "        greedy_bleu, beam_bleu, greedy_chrf, beam_chrf = compute_scores(df_, name, use_greedy = use_greedy)\n",
        "        results[name] = {\"greedy_bleu\": greedy_bleu, \"beam_bleu\": beam_bleu, \"greedy_chrf\": greedy_chrf, \"beam_chrf\": beam_chrf}\n",
        "        df_.to_csv(f\"trans_res_{name}.csv\", index=False)\n",
        "        print(\"-------\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating {name}: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f473e1a",
      "metadata": {},
      "source": [
        "## Save Translation Comaprison Results to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa0658f6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cantonese</th>\n",
              "      <th>english</th>\n",
              "      <th>greedy</th>\n",
              "      <th>beam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>我要去瞓覺喇。</td>\n",
              "      <td>I have to go to sleep.</td>\n",
              "      <td>I'm going to go to the temple.</td>\n",
              "      <td>I'm going to go to the monastery.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>我話唔定做一陣就會放棄，走去瞓晏覺算。</td>\n",
              "      <td>I may give up soon and just nap instead.</td>\n",
              "      <td>I'm going to say I will give up a fight and go...</td>\n",
              "      <td>I said I was going to do a series I would give...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>我不嬲都鍾意啲神秘啲嘅人物。</td>\n",
              "      <td>I always liked mysterious characters more.</td>\n",
              "      <td>I'm not a big fan of mysterious characters.</td>\n",
              "      <td>I don't think I've ever heard of a mysterious ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>雖然佢講咗對唔住，但係我都仲係好嬲。</td>\n",
              "      <td>Even though he apologized, I'm still furious.</td>\n",
              "      <td>I'm not sure if I can do it, but I have a good...</td>\n",
              "      <td>I'm not sure if we're going to live together, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>我唯有係等。</td>\n",
              "      <td>I can only wait.</td>\n",
              "      <td>I'm only a single one.</td>\n",
              "      <td>I'm the only one who can wait.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             cantonese                                        english  \\\n",
              "0              我要去瞓覺喇。                         I have to go to sleep.   \n",
              "1  我話唔定做一陣就會放棄，走去瞓晏覺算。       I may give up soon and just nap instead.   \n",
              "2       我不嬲都鍾意啲神秘啲嘅人物。     I always liked mysterious characters more.   \n",
              "3   雖然佢講咗對唔住，但係我都仲係好嬲。  Even though he apologized, I'm still furious.   \n",
              "4               我唯有係等。                               I can only wait.   \n",
              "\n",
              "                                              greedy  \\\n",
              "0                     I'm going to go to the temple.   \n",
              "1  I'm going to say I will give up a fight and go...   \n",
              "2        I'm not a big fan of mysterious characters.   \n",
              "3  I'm not sure if I can do it, but I have a good...   \n",
              "4                             I'm only a single one.   \n",
              "\n",
              "                                                beam  \n",
              "0                  I'm going to go to the monastery.  \n",
              "1  I said I was going to do a series I would give...  \n",
              "2  I don't think I've ever heard of a mysterious ...  \n",
              "3  I'm not sure if we're going to live together, ...  \n",
              "4                     I'm the only one who can wait.  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df.to_csv(\"trans_res_Tatoeba_mBart.csv\", index=False)\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "459848fc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot OpenSubtitles dataset using NLLB model results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "beam_sizes = [1, # greedy\n",
        "              3, 5, 7, 10] # beam search\n",
        "\n",
        "bleu_tatoeba = [24.62, 24.70, 24.79, None, None]\n",
        "chrf_tatoeba = [43.91, 44.08, 44.17, 44.18, None]\n",
        "\n",
        "bleu_opensub = [14.80, 15.43, 15.54, 15.62, 15.62]\n",
        "chrf_opensub = [34.10, 34.50, 34.75, 15.62, 34.89]\n",
        "\n",
        "tatoeba_scores = pd.DataFrame({\n",
        "    \"beam_size\": beam_sizes,\n",
        "    \"BLEU\": bleu_tatoeba,\n",
        "    \"chrf\": chrf_tatoeba\n",
        "})\n",
        "\n",
        "\n",
        "opensub_scores = pd.DataFrame({\n",
        "    \"beam_size\": beam_sizes,\n",
        "    \"BLEU\": bleu_opensub,\n",
        "    \"chrf\": chrf_opensub\n",
        "})\n",
        "def plot_scores(metric):\n",
        "    plt.figure(figsize=(10,5))\n",
        "\n",
        "    plt.plot(beam_sizes, tatoeba_scores[metric], marker=\"o\", label=\"Tatoeba\")\n",
        "    plt.plot(beam_sizes, opensub_scores[metric], marker=\"o\", label=\"Open Subtitles\")\n",
        "\n",
        "    plt.xlabel(\"Beam Size\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.title(f\"Tatoeba and OpenSubtitles vs Beam Size - {metric}\")\n",
        "    plt.xticks(beam_sizes)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_scores_dataset(score_df, dataset_name):\n",
        "    plt.figure(figsize=(10,5))\n",
        "\n",
        "    plt.plot(score_df[\"beam_size\"], score_df[\"BLEU\"], marker=\"o\", label=\"BLEU\")\n",
        "    plt.plot(score_df[\"beam_size\"], score_df[\"chrf\"], marker=\"o\", label=\"chrf\")\n",
        "\n",
        "    plt.xlabel(\"Beam Size\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.title(f\"BLEU and chrf vs Beam Size - {dataset_name}\")\n",
        "    plt.xticks(score_df[\"beam_size\"])\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "plot_scores(\"BLEU\")\n",
        "plot_scores(\"chrf\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "MSE_446",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
